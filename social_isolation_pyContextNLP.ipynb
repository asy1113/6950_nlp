{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence_rules='KB/rush_rules.tsv'\n",
    "#target_rules='KB/social_kb.yml'\n",
    "#context_rules='KB/general_modifiers.yml'\n",
    "#feature_inference_rule='KB/featurer_inferences.csv'\n",
    "#document_inference_rule='KB/doc_inferences.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('KB/social_target_rules_040618.yml','r') as f:\n",
    "    target_rules = f.read()\n",
    "with open('KB/general_modifiers_2018.yml','r') as f:   # KB/lexical_kb_05042016.yml , KB/general_modifiers_2018.yml\n",
    "    context_rules = f.read()\n",
    "with open('KB/featurer_inferences.csv','r') as f:     \n",
    "    feature_inference_rule = f.read()\n",
    "with open('KB/doc_inferences.csv','r') as f:  \n",
    "    document_inference_rule = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pynlp_pipe import Mypipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myPipe=Mypipe(sentence_rules, target_rules, context_rules, feature_inference_rule, document_inference_rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#path =\"C:/Users/HuaiZhong/2017/social/noisolation\"\n",
    "#path = \"C:/Users/HuaiZhong/2017/social/isolation\"\n",
    "path = \"test\"\n",
    "files = os.listdir(path)\n",
    "#files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read documents and apply pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import chardet\n",
    "\n",
    "results=dict()  # dictionary will contain document names as keys and a document-level classification as values.\n",
    "context_doc_res=[]\n",
    "\n",
    "# Read txt files\n",
    "doc_texts = []\n",
    "note_count = 0                       # count the number of text notes want to process ***\n",
    "for i in files[:]:\n",
    "    if \".txt\" in i:\n",
    "        note_count = note_count + 1  #\n",
    "        if note_count > 20:          # count the number of text notes want to process ***\n",
    "            break                    #\n",
    "        with open(os.path.join(path,i), 'rb') as f:\n",
    "            doc_txt = chardet.detect(f.read()) \n",
    "        #print(i)\n",
    "        #print(result[\"encoding\"])        \n",
    "        \n",
    "        with open(os.path.join(path,i),encoding=doc_txt[\"encoding\"]) as f:\n",
    "            doc_text = f.read()  # or readline if the file is large     \n",
    "            doc_text=doc_text.replace('\\n', ' ')\n",
    "                        \n",
    "            doc_class, context_doc, annotations, relations = myPipe.process(doc_text)\n",
    "            \n",
    "            results[i] = doc_class\n",
    "            context_doc_res.append(context_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print classification results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06826804_201357372_516733971.txt  :  no_isolation\n",
      "10376465_211542418_758234626.txt  :  no_isolation\n",
      "10429082_201673089_524442823.txt  :  isolation_doc\n",
      "11856804_198848405_455756533.txt  :  no_isolation\n",
      "12962676_204132809_583173986.txt  :  no_isolation\n",
      "13087762_208414890_695000247.txt  :  isolation_doc\n",
      "14193973_203894648_577416893.txt  :  isolation_doc\n",
      "14210991_203425675_568754174.txt  :  isolation_doc\n",
      "14749485_199614496_472563924.txt  :  isolation_doc\n",
      "15014962_215502471_840797249.txt  :  isolation_doc\n"
     ]
    }
   ],
   "source": [
    "for j in results:\n",
    "    print(j, \" : \", results[j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "posPath =\"test/testp\"\n",
    "negPath = \"test/testn\"\n",
    "posLab = \"isolation_doc\"\n",
    "negLab = \"no_isolation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pynlp_valid import Validnote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validnote = Validnote()\n",
    "std_doc = validnote.readstd(posPath, negPath, posLab, negLab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "F1:  1.0\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1 = validnote.validation(results, std_doc, posLab, negLab)\n",
    "print(\"*\"*20)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6950"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install PyRuSH\n",
    "# !pip install pyConTextNLP\n",
    "# !pip install textblob\n",
    "# !pip install radnlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_rules='KB/rush_rules.tsv'\n",
    "#target_rules='KB/social_kb.yml'\n",
    "#context_rules='KB/general_modifiers.yml'\n",
    "#feature_inference_rule='KB/featurer_inferences.csv'\n",
    "#document_inference_rule='KB/doc_inferences.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('KB/social_target_rules_042118.yml','r') as f:   # 'KB/social_target_rules_040618.yml'\n",
    "    target_rules = f.read()\n",
    "with open('KB/social_modifiers_2018.yml','r') as f:   # KB/lexical_kb_05042016.yml , KB/general_modifiers_2018.yml\n",
    "    context_rules = f.read()\n",
    "with open('KB/featurer_inferences.csv','r') as f:     \n",
    "    feature_inference_rule = f.read()\n",
    "with open('KB/doc_inferences.csv','r') as f:  \n",
    "    document_inference_rule = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynlp_pipe import Mypipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "myPipe=Mypipe(sentence_rules, target_rules, context_rules, feature_inference_rule, document_inference_rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "#path =\"test/2017/combine\"                    # 2017 96+439\n",
    "path = \"test/500_1/corpus\"                    # 500 notes\n",
    "#path = \"test/156_156/soc\"                    # combine positive\n",
    "\n",
    "files = os.listdir(path)\n",
    "len(files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read documents and apply pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chardet\n",
    "\n",
    "results=dict()  # dictionary will contain document names as keys and a document-level classification as values.\n",
    "context_doc_res=[]\n",
    "\n",
    "# Read txt files\n",
    "doc_texts = []\n",
    "#note_count = 0                       # count the number of text notes want to process ***\n",
    "for i in files[:]:\n",
    "    if \".txt\" in i:\n",
    "        #note_count = note_count + 1  #\n",
    "        #if note_count > 20:          # count the number of text notes want to process ***\n",
    "        #    break                    #\n",
    "        with open(os.path.join(path,i), 'rb') as f:\n",
    "            doc_txt = chardet.detect(f.read()) \n",
    "        #print(i)\n",
    "        #print(result[\"encoding\"])        \n",
    "        \n",
    "        with open(os.path.join(path,i),encoding=doc_txt[\"encoding\"]) as f:\n",
    "            doc_text = f.read()  # or readline if the file is large     \n",
    "            doc_text=doc_text.replace('\\n', ' ')\n",
    "                        \n",
    "            doc_class, context_doc, annotations, relations = myPipe.process(doc_text)\n",
    "            if len(annotations) != 0 and doc_class == 'no_isolation':\n",
    "                print (i)\n",
    "            results[i] = doc_class\n",
    "            context_doc_res.append(context_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print classification results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09696212_199472695_469775619.txt  :  isolation_doc\n",
      "09910266_203543374_585135519.txt  :  isolation_doc\n",
      "09914912_202033473_535253049.txt  :  isolation_doc\n",
      "10882066_216071107_853913484.txt  :  no_isolation\n",
      "10882066_216071107_859257422.txt  :  no_isolation\n",
      "10882066_216071107_863455238.txt  :  no_isolation\n"
     ]
    }
   ],
   "source": [
    "res_num=0\n",
    "for j in results:\n",
    "    print(j, \" : \", results[j])\n",
    "    res_num=res_num+1\n",
    "    if res_num > 5:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "posPath =\"test/500_1/corpusp\"      # 500 notes\n",
    "#posPath =\"test/2017/isolation\"     # 2017 96+439\n",
    "#posPath =\"test/156_156/soc_pos\"    # combine positive\n",
    "negPath = \"test/500_1/corpusn\"     # 500 notes\n",
    "#negPath = \"test/2017/noisolation\"  # 2017 96+439\n",
    "#negPath =\"test/156_156/soc_neg\"    # combine positive\n",
    "\n",
    "posLab = \"isolation_doc\"\n",
    "negLab = \"no_isolation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynlp_valid import Validnote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "validnote = Validnote()\n",
    "std_doc = validnote.readstd(posPath, negPath, posLab, negLab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fn: 11016888_205116311_615981390.txt\n",
      "fp: 14144257_216657674_865911455.txt\n",
      "fp: 14260145_211642830_760314646.txt\n",
      "fp: 14498364_203097610_559618901.txt\n",
      "fn: 15157993_211465548_756717735.txt\n",
      "fn: 20427474_205942535_631639605.txt\n",
      "fn: 20530486_199785789_477860675.txt\n",
      "fn: 20841417_202481581_544378727.txt\n",
      "fn: 20878801_211192075_752731208.txt\n",
      "fn: 20960880_208010073_683357038.txt\n",
      "fn: 21020299_210268292_734687814.txt\n",
      "fn: 21030541_210790602_762893652.txt\n",
      "fn: 21057691_211766501_765109852.txt\n",
      "------------------------------\n",
      "\tReference \t Total\n",
      "------------------------------\n",
      "System \t 50 \t 3 \t 53\n",
      "System \t 10 \t 57 \t 67\n",
      "------------------------------\n",
      "Total \t 60 \t 60\n",
      "------------------------------\n",
      "********************\n",
      "Precision:  0.9433962264150944\n",
      "Recall:  0.8333333333333334\n",
      "F1:  0.8849557522123894\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1 = validnote.validation(results, std_doc, posLab, negLab)\n",
    "print(\"*\"*20)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(path,\"14498364_203097610_559618901.txt\")) as f:\n",
    "    doc_text = f.read()      \n",
    "    doc_text=doc_text.replace('\\n', ' ')                        \n",
    "    doc_class, context_doc, annotations, relations = myPipe.process(doc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>markup_id</th>\n",
       "      <th>vis_category</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>txt</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T0</td>\n",
       "      <td>Target</td>\n",
       "      <td>68</td>\n",
       "      <td>79</td>\n",
       "      <td>felt lonely</td>\n",
       "      <td>isolation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  markup_id vis_category start end          txt       type\n",
       "0        T0       Target    68  79  felt lonely  isolation"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relation_id</th>\n",
       "      <th>type</th>\n",
       "      <th>arg1_cate</th>\n",
       "      <th>arg1_id</th>\n",
       "      <th>arg2_cate</th>\n",
       "      <th>arg2_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [relation_id, type, arg1_cate, arg1_id, arg2_cate, arg2_id]\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

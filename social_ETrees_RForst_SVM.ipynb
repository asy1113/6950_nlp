{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "import math\n",
    "import chardet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "439\n"
     ]
    }
   ],
   "source": [
    "path =\"C:/Users/hp/social/noisolation\"\n",
    " \n",
    "files = os.listdir(path)\n",
    "files\n",
    "\n",
    "note =[]\n",
    "\n",
    "for i in files[:]:\n",
    "    if \".txt\" in i:\n",
    "        with open(os.path.join(path,i), 'rb') as f:\n",
    "            result = chardet.detect(f.read()) \n",
    "        #print(i)\n",
    "        #print(result[\"encoding\"])        \n",
    "        \n",
    "        with open(os.path.join(path,i),encoding=result[\"encoding\"]) as f:\n",
    "            result = f.read()  # or readline if the file is large\n",
    "\n",
    "        note.append(result)\n",
    "#print(note)\n",
    "print(len(note))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "social_no = pd.DataFrame({\"document\":note,\"label\":np.repeat(0,len(note))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = \"C:/Users/hp/social/isolation\"\n",
    " \n",
    "files = os.listdir(path)\n",
    "files\n",
    "\n",
    "note1=[]\n",
    "\n",
    "for i in files[:]:\n",
    "    if \".txt\" in i:\n",
    "        with open(os.path.join(path,i) ,'rb') as f:\n",
    "            result = chardet.detect(f.read()) \n",
    "        #print(i)\n",
    "        #print(result[\"encoding\"])\n",
    "\n",
    "        with open(os.path.join(path,i),encoding=result[\"encoding\"]) as f:\n",
    "            result = f.read()  # or readline if the file is large\n",
    "\n",
    "        note1.append(result)\n",
    "        \n",
    "print(len(note1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "social_yes = pd.DataFrame({\"document\":note1,\"label\":np.repeat(1,len(note1))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nall_data = social_no.append(social_yes)\\nprint(len(all_data))\\nprint(all_data[:3])\\nprint(all_data[-3:-1])\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select all 439 nosocial notes and add to all_list\n",
    "\"\"\"\n",
    "all_data = social_no.append(social_yes)\n",
    "print(len(all_data))\n",
    "print(all_data[:3])\n",
    "print(all_data[-3:-1])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196\n",
      "                                             document  label\n",
      "6   Psychiatric Attending Daily Progress Note     ...      0\n",
      "59  Behavior Health Clinical Intake Transfer Note ...      0\n",
      "84  Psychology Progress Note     Admission Date: 9...      0\n",
      "                                             document  label\n",
      "93  Psychiatric Attending Daily Progress Note     ...      1\n",
      "94  TRANSFER OF CARE NOTE    Admission:   Please s...      1\n"
     ]
    }
   ],
   "source": [
    "# random select 100 nosocial notes and add to all_list\n",
    "\n",
    "#all_data = social_no.append(social_yes)\n",
    "\n",
    "# random choice social_no notes with the same number of social notes (96)\n",
    "\n",
    "import random\n",
    "\n",
    "s_no_select = social_no.iloc[np.random.choice(len(social_yes)+4, replace=False, size=(len(social_yes))+4)]\n",
    "\n",
    "all_data = s_no_select.append(social_yes)\n",
    "\n",
    "print(len(all_data))\n",
    "print(all_data[:3])\n",
    "print(all_data[-3:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpusList=all_data[all_data.columns[0]].tolist()\n",
    "labels=all_data[all_data.columns[1]].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = [ token for token in tokens if re.search('(^[a-zA-Z]+$)', token) ]\n",
    "    a=[]\n",
    "    for i in filtered_tokens:\n",
    "        a.append(WordNetLemmatizer().lemmatize(i,'v'))\n",
    "    return a\n",
    "    #return filtered_tokens\n",
    "\n",
    "\n",
    "cachedStopWords = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(196, 77689)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = TfidfVectorizer(lowercase=True,\n",
    "                     ngram_range=(1, 3), preprocessor=None, stop_words='english',\n",
    "                     strip_accents=None, tokenizer=tokenize, vocabulary=None)\n",
    "X1 = cv.fit_transform(corpusList)\n",
    "print(X1.shape)\n",
    "print()\n",
    "lexicon = cv.get_feature_names()\n",
    "#print (lexicon)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(196, 77689)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=X1  ## for select fetures \n",
    "print(x.shape)\n",
    "\n",
    "Y = np.array(labels)\n",
    "Y  ## class level \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(196, 77689)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(196, 600)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "print(x.shape)\n",
    "\n",
    "X_new = SelectKBest(chi2, k=600).fit_transform(x, Y)   # select 400 features\n",
    "X_new.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(196, 600)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=X_new        # make unque name for next cell \n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ExtraTreesClassifier'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"ExtraTreesClassifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model  0 : ExtraTreesClassifier = 10\n",
      "   Fold 1 accuracy: 60.00 %\n",
      "   Fold 2 accuracy: 65.00 %\n",
      "   Fold 3 accuracy: 75.00 %\n",
      "   Fold 4 accuracy: 75.00 %\n",
      "   Fold 5 accuracy: 70.00 %\n",
      "   Fold 6 accuracy: 75.00 %\n",
      "   Fold 7 accuracy: 68.42 %\n",
      "   Fold 8 accuracy: 84.21 %\n",
      "   Fold 9 accuracy: 52.63 %\n",
      "   Fold 10 accuracy: 84.21 %\n",
      "     Overall test accuracy: 70.92 %\n",
      "     Overall training accuracy: 100.00 %\n",
      "model  1 : ExtraTreesClassifier = 30\n",
      "   Fold 1 accuracy: 70.00 %\n",
      "   Fold 2 accuracy: 65.00 %\n",
      "   Fold 3 accuracy: 80.00 %\n",
      "   Fold 4 accuracy: 70.00 %\n",
      "   Fold 5 accuracy: 80.00 %\n",
      "   Fold 6 accuracy: 90.00 %\n",
      "   Fold 7 accuracy: 78.95 %\n",
      "   Fold 8 accuracy: 84.21 %\n",
      "   Fold 9 accuracy: 68.42 %\n",
      "   Fold 10 accuracy: 68.42 %\n",
      "     Overall test accuracy: 75.51 %\n",
      "     Overall training accuracy: 100.00 %\n",
      "model  2 : ExtraTreesClassifier = 60\n",
      "   Fold 1 accuracy: 70.00 %\n",
      "   Fold 2 accuracy: 80.00 %\n",
      "   Fold 3 accuracy: 80.00 %\n",
      "   Fold 4 accuracy: 70.00 %\n",
      "   Fold 5 accuracy: 75.00 %\n",
      "   Fold 6 accuracy: 80.00 %\n",
      "   Fold 7 accuracy: 73.68 %\n",
      "   Fold 8 accuracy: 68.42 %\n",
      "   Fold 9 accuracy: 68.42 %\n",
      "   Fold 10 accuracy: 89.47 %\n",
      "     Overall test accuracy: 75.51 %\n",
      "     Overall training accuracy: 100.00 %\n",
      "model  3 : ExtraTreesClassifier = 100\n",
      "   Fold 1 accuracy: 60.00 %\n",
      "   Fold 2 accuracy: 85.00 %\n",
      "   Fold 3 accuracy: 85.00 %\n",
      "   Fold 4 accuracy: 75.00 %\n",
      "   Fold 5 accuracy: 70.00 %\n",
      "   Fold 6 accuracy: 85.00 %\n",
      "   Fold 7 accuracy: 84.21 %\n",
      "   Fold 8 accuracy: 68.42 %\n",
      "   Fold 9 accuracy: 78.95 %\n",
      "   Fold 10 accuracy: 84.21 %\n",
      "     Overall test accuracy: 77.55 %\n",
      "     Overall training accuracy: 100.00 %\n",
      "model  4 : ExtraTreesClassifier = 300\n",
      "   Fold 1 accuracy: 55.00 %\n",
      "   Fold 2 accuracy: 75.00 %\n",
      "   Fold 3 accuracy: 90.00 %\n",
      "   Fold 4 accuracy: 80.00 %\n",
      "   Fold 5 accuracy: 90.00 %\n",
      "   Fold 6 accuracy: 85.00 %\n",
      "   Fold 7 accuracy: 63.16 %\n",
      "   Fold 8 accuracy: 68.42 %\n",
      "   Fold 9 accuracy: 63.16 %\n",
      "   Fold 10 accuracy: 63.16 %\n",
      "     Overall test accuracy: 73.47 %\n",
      "     Overall training accuracy: 100.00 %\n",
      "model  5 : ExtraTreesClassifier = 500\n",
      "   Fold 1 accuracy: 75.00 %\n",
      "   Fold 2 accuracy: 75.00 %\n",
      "   Fold 3 accuracy: 75.00 %\n",
      "   Fold 4 accuracy: 60.00 %\n",
      "   Fold 5 accuracy: 80.00 %\n",
      "   Fold 6 accuracy: 70.00 %\n",
      "   Fold 7 accuracy: 78.95 %\n",
      "   Fold 8 accuracy: 63.16 %\n",
      "   Fold 9 accuracy: 78.95 %\n",
      "   Fold 10 accuracy: 63.16 %\n",
      "     Overall test accuracy: 71.94 %\n",
      "     Overall training accuracy: 100.00 %\n"
     ]
    }
   ],
   "source": [
    "model=0\n",
    "results = []\n",
    "cont = []\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "trees = [10, 30, 60, 100, 300, 500]\n",
    "for t in range(len(trees)):\n",
    "    fold = 1\n",
    "    truth = []\n",
    "    rf_prediction = []\n",
    "    print(\"model \", t, \": ExtraTreesClassifier = \" + str(trees[t]))\n",
    "    test_count = 0\n",
    "    rf = ExtraTreesClassifier(bootstrap=False,\n",
    "           criterion='entropy', max_depth=15, max_features=0.9,\n",
    "           max_leaf_nodes=None, min_impurity_decrease=1e-045,\n",
    "           min_samples_leaf=1, min_samples_split=3,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=trees[t], n_jobs=-1,\n",
    "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
    "    for train_idx, test_idx in kf.split(X):\n",
    "        trainX = X[train_idx]\n",
    "        trainY = Y[train_idx]\n",
    "        testX = X[test_idx]\n",
    "        testY = Y[test_idx]\n",
    "        truth.append(testY)\n",
    "        rf.fit(trainX, trainY)\n",
    "        Y_hat = rf.predict(testX)\n",
    "        rf_prediction.append(Y_hat)\n",
    "        print(\"   Fold %d accuracy: %.2f %%\" % (fold, ((np.sum(Y_hat == testY)/len(testY)) * 100.0)))                        \n",
    "        fold += 1\n",
    "    truth = np.concatenate(truth, axis=0)    \n",
    "    rf_prediction = np.concatenate(rf_prediction, axis=0)\n",
    "    test_results = np.sum(rf_prediction == truth)/len(truth)\n",
    "    print(\"     Overall test accuracy: %.2f %%\" % (test_results * 100))  \n",
    "    rf = rf.fit(X, Y)\n",
    "    Y_hat = rf.predict(X)\n",
    "    train_results = np.sum(Y_hat == Y)/len(Y)\n",
    "    print(\"     Overall training accuracy: %.2f %%\" % (train_results * 100.0))  \n",
    "    results.append([train_results, test_results])   \n",
    "    cont.append([truth, rf_prediction])\n",
    "    \n",
    "    \n",
    "    \n",
    "### this case is not 88%, it will be a liitle bit diffenet. but not too much "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Best Model: 3\n",
      "\n",
      "ExtraTrees\n",
      "         no  social  Total\n",
      "no       83      27    110\n",
      "social   17      69     86\n",
      "Total   100      96    196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = input(\"Enter Best Model: \")\n",
    "best = cont[int(model)]\n",
    "rf_ct = pd.crosstab(best[1], best[0], margins=True)\n",
    "rf_ct.columns = [\"no\", \"social\", \"Total\"]\n",
    "rf_ct.index = [\"no\", \"social\", \"Total\"]\n",
    "print()\n",
    "print(\"ExtraTrees\")\n",
    "print(rf_ct)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[83 17]\n",
      " [27 69]]\n",
      "0.758241758242\n",
      "0.71875\n",
      "0.802325581395\n",
      "0.775510204082\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.83      0.79       100\n",
      "          1       0.80      0.72      0.76        96\n",
      "\n",
      "avg / total       0.78      0.78      0.77       196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score,f1_score,precision_score,accuracy_score,classification_report\n",
    "y_true =cont[int(model)][0]\n",
    "y_pred = cont[int(model)][1]\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(f1_score(y_true, y_pred) )\n",
    "\n",
    "\n",
    "\n",
    "print(recall_score(y_true, y_pred),   )\n",
    "print(precision_score(y_true, y_pred))\n",
    "print(accuracy_score(y_true, y_pred))\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTrees: Sensitivity: 0.71875 Specificity: 0.83000 PPV: 0.80233 NPV: 0.75455 Accuracy: 0.77551\n"
     ]
    }
   ],
   "source": [
    "Sens = rf_ct.iloc[1][1]/rf_ct.iloc[2][1]\n",
    "Spec = rf_ct.iloc[0][0]/rf_ct.iloc[2][0]\n",
    "PPV = rf_ct.iloc[1][1]/rf_ct.iloc[1][2]\n",
    "NPV = rf_ct.iloc[0][0]/rf_ct.iloc[0][2]\n",
    "ACC = (rf_ct.iloc[0][0] + rf_ct.iloc[1][1]) / rf_ct.iloc[2][2]\n",
    "print(\"ExtraTrees: Sensitivity: %.5f Specificity: %.5f PPV: %.5f NPV: %.5f Accuracy: %.5f\" % (Sens, Spec, PPV, NPV, ACC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJIxCEARBUCSMQhAEQVDkL3VyIjYDcqUoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27b9693cba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC =  0.774375\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rf_fpr, rf_tpr, rf_thresholds = roc_curve(best[0], best[1], pos_label=1)\n",
    "roc_auc = auc(rf_fpr, rf_tpr)\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(rf_fpr, rf_tpr, label='ExtraTrees')\n",
    "plt.xlabel('False positive rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "print(\"AUC = \", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SVM'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"SVM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 0: SVM RBF Gamma=1.000 C=1.00\n",
      "   Fold 1 accuracy: 85.00 %\n",
      "   Fold 2 accuracy: 80.00 %\n",
      "   Fold 3 accuracy: 65.00 %\n",
      "   Fold 4 accuracy: 75.00 %\n",
      "   Fold 5 accuracy: 55.00 %\n",
      "   Fold 6 accuracy: 60.00 %\n",
      "   Fold 7 accuracy: 73.68 %\n",
      "   Fold 8 accuracy: 73.68 %\n",
      "   Fold 9 accuracy: 52.63 %\n",
      "   Fold 10 accuracy: 73.68 %\n",
      "     Overall test accuracy: 69.39 %\n",
      "     Overall training accuracy: 76.02 %\n",
      "model 1: SVM RBF Gamma=1.000 C=2.00\n",
      "   Fold 1 accuracy: 80.00 %\n",
      "   Fold 2 accuracy: 55.00 %\n",
      "   Fold 3 accuracy: 80.00 %\n",
      "   Fold 4 accuracy: 80.00 %\n",
      "   Fold 5 accuracy: 60.00 %\n",
      "   Fold 6 accuracy: 55.00 %\n",
      "   Fold 7 accuracy: 78.95 %\n",
      "   Fold 8 accuracy: 68.42 %\n",
      "   Fold 9 accuracy: 84.21 %\n",
      "   Fold 10 accuracy: 63.16 %\n",
      "     Overall test accuracy: 70.41 %\n",
      "     Overall training accuracy: 79.08 %\n",
      "model 2: SVM RBF Gamma=1.000 C=4.00\n",
      "   Fold 1 accuracy: 55.00 %\n",
      "   Fold 2 accuracy: 80.00 %\n",
      "   Fold 3 accuracy: 70.00 %\n",
      "   Fold 4 accuracy: 55.00 %\n",
      "   Fold 5 accuracy: 60.00 %\n",
      "   Fold 6 accuracy: 65.00 %\n",
      "   Fold 7 accuracy: 57.89 %\n",
      "   Fold 8 accuracy: 89.47 %\n",
      "   Fold 9 accuracy: 78.95 %\n",
      "   Fold 10 accuracy: 100.00 %\n",
      "     Overall test accuracy: 70.92 %\n",
      "     Overall training accuracy: 87.24 %\n",
      "model 3: SVM RBF Gamma=1.000 C=6.00\n",
      "   Fold 1 accuracy: 55.00 %\n",
      "   Fold 2 accuracy: 90.00 %\n",
      "   Fold 3 accuracy: 80.00 %\n",
      "   Fold 4 accuracy: 50.00 %\n",
      "   Fold 5 accuracy: 90.00 %\n",
      "   Fold 6 accuracy: 70.00 %\n",
      "   Fold 7 accuracy: 84.21 %\n",
      "   Fold 8 accuracy: 73.68 %\n",
      "   Fold 9 accuracy: 84.21 %\n",
      "   Fold 10 accuracy: 63.16 %\n",
      "     Overall test accuracy: 73.98 %\n",
      "     Overall training accuracy: 91.84 %\n",
      "model 4: SVM RBF Gamma=1.000 C=8.00\n",
      "   Fold 1 accuracy: 80.00 %\n",
      "   Fold 2 accuracy: 65.00 %\n",
      "   Fold 3 accuracy: 85.00 %\n",
      "   Fold 4 accuracy: 70.00 %\n",
      "   Fold 5 accuracy: 65.00 %\n",
      "   Fold 6 accuracy: 70.00 %\n",
      "   Fold 7 accuracy: 68.42 %\n",
      "   Fold 8 accuracy: 84.21 %\n",
      "   Fold 9 accuracy: 78.95 %\n",
      "   Fold 10 accuracy: 73.68 %\n",
      "     Overall test accuracy: 73.98 %\n",
      "     Overall training accuracy: 92.35 %\n",
      "model 5: SVM RBF Gamma=1.000 C=10.00\n",
      "   Fold 1 accuracy: 85.00 %\n",
      "   Fold 2 accuracy: 85.00 %\n",
      "   Fold 3 accuracy: 70.00 %\n",
      "   Fold 4 accuracy: 60.00 %\n",
      "   Fold 5 accuracy: 80.00 %\n",
      "   Fold 6 accuracy: 85.00 %\n",
      "   Fold 7 accuracy: 63.16 %\n",
      "   Fold 8 accuracy: 84.21 %\n",
      "   Fold 9 accuracy: 73.68 %\n",
      "   Fold 10 accuracy: 63.16 %\n",
      "     Overall test accuracy: 75.00 %\n",
      "     Overall training accuracy: 93.37 %\n",
      "model 6: SVM RBF Gamma=2.000 C=1.00\n",
      "   Fold 1 accuracy: 70.00 %\n",
      "   Fold 2 accuracy: 75.00 %\n",
      "   Fold 3 accuracy: 80.00 %\n",
      "   Fold 4 accuracy: 65.00 %\n",
      "   Fold 5 accuracy: 45.00 %\n",
      "   Fold 6 accuracy: 70.00 %\n",
      "   Fold 7 accuracy: 94.74 %\n",
      "   Fold 8 accuracy: 73.68 %\n",
      "   Fold 9 accuracy: 68.42 %\n",
      "   Fold 10 accuracy: 68.42 %\n",
      "     Overall test accuracy: 70.92 %\n",
      "     Overall training accuracy: 78.57 %\n",
      "model 7: SVM RBF Gamma=2.000 C=2.00\n",
      "   Fold 1 accuracy: 80.00 %\n",
      "   Fold 2 accuracy: 75.00 %\n",
      "   Fold 3 accuracy: 75.00 %\n",
      "   Fold 4 accuracy: 70.00 %\n",
      "   Fold 5 accuracy: 80.00 %\n",
      "   Fold 6 accuracy: 60.00 %\n",
      "   Fold 7 accuracy: 52.63 %\n",
      "   Fold 8 accuracy: 68.42 %\n",
      "   Fold 9 accuracy: 78.95 %\n",
      "   Fold 10 accuracy: 68.42 %\n",
      "     Overall test accuracy: 70.92 %\n",
      "     Overall training accuracy: 85.71 %\n",
      "model 8: SVM RBF Gamma=2.000 C=4.00\n",
      "   Fold 1 accuracy: 75.00 %\n",
      "   Fold 2 accuracy: 70.00 %\n",
      "   Fold 3 accuracy: 70.00 %\n",
      "   Fold 4 accuracy: 65.00 %\n",
      "   Fold 5 accuracy: 90.00 %\n",
      "   Fold 6 accuracy: 85.00 %\n",
      "   Fold 7 accuracy: 84.21 %\n",
      "   Fold 8 accuracy: 52.63 %\n",
      "   Fold 9 accuracy: 78.95 %\n",
      "   Fold 10 accuracy: 68.42 %\n",
      "     Overall test accuracy: 73.98 %\n",
      "     Overall training accuracy: 92.35 %\n",
      "model 9: SVM RBF Gamma=2.000 C=6.00\n",
      "   Fold 1 accuracy: 85.00 %\n",
      "   Fold 2 accuracy: 80.00 %\n",
      "   Fold 3 accuracy: 80.00 %\n",
      "   Fold 4 accuracy: 75.00 %\n",
      "   Fold 5 accuracy: 80.00 %\n",
      "   Fold 6 accuracy: 60.00 %\n",
      "   Fold 7 accuracy: 78.95 %\n",
      "   Fold 8 accuracy: 78.95 %\n",
      "   Fold 9 accuracy: 63.16 %\n",
      "   Fold 10 accuracy: 73.68 %\n",
      "     Overall test accuracy: 75.51 %\n",
      "     Overall training accuracy: 93.88 %\n",
      "model 10: SVM RBF Gamma=2.000 C=8.00\n",
      "   Fold 1 accuracy: 85.00 %\n",
      "   Fold 2 accuracy: 80.00 %\n",
      "   Fold 3 accuracy: 85.00 %\n",
      "   Fold 4 accuracy: 90.00 %\n",
      "   Fold 5 accuracy: 70.00 %\n",
      "   Fold 6 accuracy: 75.00 %\n",
      "   Fold 7 accuracy: 84.21 %\n",
      "   Fold 8 accuracy: 84.21 %\n",
      "   Fold 9 accuracy: 36.84 %\n",
      "   Fold 10 accuracy: 78.95 %\n",
      "     Overall test accuracy: 77.04 %\n",
      "     Overall training accuracy: 95.41 %\n",
      "model 11: SVM RBF Gamma=2.000 C=10.00\n",
      "   Fold 1 accuracy: 75.00 %\n",
      "   Fold 2 accuracy: 95.00 %\n",
      "   Fold 3 accuracy: 70.00 %\n",
      "   Fold 4 accuracy: 75.00 %\n",
      "   Fold 5 accuracy: 65.00 %\n",
      "   Fold 6 accuracy: 95.00 %\n",
      "   Fold 7 accuracy: 63.16 %\n",
      "   Fold 8 accuracy: 68.42 %\n",
      "   Fold 9 accuracy: 84.21 %\n",
      "   Fold 10 accuracy: 78.95 %\n",
      "     Overall test accuracy: 77.04 %\n",
      "     Overall training accuracy: 96.94 %\n"
     ]
    }
   ],
   "source": [
    "model = 0\n",
    "cont = []\n",
    "results = pd.DataFrame(columns=('name', 'accuracy'))\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "C = [1,2,4,6,8,10]\n",
    "gamma = [1,2]  \n",
    "for g in range(len(gamma)):\n",
    "    acc = []\n",
    "    name = \"SVM RBF Gamma=%.3f\" % (gamma[g])     \n",
    "    for c in range(len(C)):\n",
    "        fold = 1\n",
    "        truth = []\n",
    "        svm_prediction = []\n",
    "        print(\"model %d: SVM RBF Gamma=%.3f C=%.2f\" % (model, gamma[g], C[c]))        \n",
    "        test_count = 0\n",
    "        svm = SVC(C=C[c], kernel='rbf', gamma=gamma[g])\n",
    "        for train_idx, test_idx in kf.split(X):\n",
    "            trainX = X[train_idx]\n",
    "            trainY = Y[train_idx]\n",
    "            testX = X[test_idx]\n",
    "            testY = Y[test_idx]\n",
    "            truth.append(testY)\n",
    "            svm.fit(trainX, trainY)\n",
    "            Y_hat = svm.predict(testX)\n",
    "            svm_prediction.append(Y_hat)\n",
    "            print(\"   Fold %d accuracy: %.2f %%\" % (fold, ((np.sum(Y_hat == testY)/len(testY)) * 100.0)))                        \n",
    "            fold += 1\n",
    "        truth = np.concatenate(truth, axis=0)    \n",
    "        svm_prediction = np.concatenate(svm_prediction, axis=0)\n",
    "        test_results = np.sum(svm_prediction == truth)/len(truth)\n",
    "        print(\"     Overall test accuracy: %.2f %%\" % (test_results * 100))  \n",
    "        svm = svm.fit(X, Y)\n",
    "        Y_hat = svm.predict(X)\n",
    "        train_results = np.sum(Y_hat == Y)/len(Y)\n",
    "        print(\"     Overall training accuracy: %.2f %%\" % (train_results * 100.0))  \n",
    "        acc.append([train_results, test_results])   \n",
    "        cont.append([truth, svm_prediction])\n",
    "        model += 1\n",
    "    results = results.append({'name': name, 'accuracy' : acc}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Best Model: 11\n",
      "\n",
      "SVM\n",
      "         no  social  Total\n",
      "no       83      28    111\n",
      "social   17      68     85\n",
      "Total   100      96    196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = input(\"Enter Best Model: \")\n",
    "best = cont[int(model)]\n",
    "rf_ct = pd.crosstab(best[1], best[0], margins=True)\n",
    "rf_ct.columns = [\"no\", \"social\", \"Total\"]\n",
    "rf_ct.index = [\"no\", \"social\", \"Total\"]\n",
    "print()\n",
    "print(\"SVM\")\n",
    "print(rf_ct)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Sensitivity: 0.70833 Specificity: 0.83000 PPV: 0.80000 NPV: 0.74775 Accuracy: 0.77041\n"
     ]
    }
   ],
   "source": [
    "Sens = rf_ct.iloc[1][1]/rf_ct.iloc[2][1]\n",
    "Spec = rf_ct.iloc[0][0]/rf_ct.iloc[2][0]\n",
    "PPV = rf_ct.iloc[1][1]/rf_ct.iloc[1][2]\n",
    "NPV = rf_ct.iloc[0][0]/rf_ct.iloc[0][2]\n",
    "ACC = (rf_ct.iloc[0][0] + rf_ct.iloc[1][1]) / rf_ct.iloc[2][2]\n",
    "print(\"Random Forest: Sensitivity: %.5f Specificity: %.5f PPV: %.5f NPV: %.5f Accuracy: %.5f\" % (Sens, Spec, PPV, NPV, ACC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[83 17]\n",
      " [28 68]]\n",
      "0.75138121547\n",
      "0.708333333333\n",
      "0.8\n",
      "0.770408163265\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.83      0.79       100\n",
      "          1       0.80      0.71      0.75        96\n",
      "\n",
      "avg / total       0.77      0.77      0.77       196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score,f1_score,precision_score,accuracy_score,classification_report\n",
    "y_true =cont[int(model)][0]\n",
    "y_pred = cont[int(model)][1]\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(f1_score(y_true, y_pred) )\n",
    "\n",
    "\n",
    "\n",
    "print(recall_score(y_true, y_pred),   )\n",
    "print(precision_score(y_true, y_pred))\n",
    "print(accuracy_score(y_true, y_pred))\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RandomForest'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"RandomForest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model  0 : Random Forest trees = 5\n",
      "   Fold 1 accuracy: 70.00 %\n",
      "   Fold 2 accuracy: 65.00 %\n",
      "   Fold 3 accuracy: 65.00 %\n",
      "   Fold 4 accuracy: 75.00 %\n",
      "   Fold 5 accuracy: 90.00 %\n",
      "   Fold 6 accuracy: 80.00 %\n",
      "   Fold 7 accuracy: 78.95 %\n",
      "   Fold 8 accuracy: 57.89 %\n",
      "   Fold 9 accuracy: 89.47 %\n",
      "   Fold 10 accuracy: 73.68 %\n",
      "     Overall test accuracy: 74.49 %\n",
      "     Overall training accuracy: 97.45 %\n",
      "model  1 : Random Forest trees = 10\n",
      "   Fold 1 accuracy: 85.00 %\n",
      "   Fold 2 accuracy: 80.00 %\n",
      "   Fold 3 accuracy: 60.00 %\n",
      "   Fold 4 accuracy: 65.00 %\n",
      "   Fold 5 accuracy: 80.00 %\n",
      "   Fold 6 accuracy: 75.00 %\n",
      "   Fold 7 accuracy: 84.21 %\n",
      "   Fold 8 accuracy: 68.42 %\n",
      "   Fold 9 accuracy: 68.42 %\n",
      "   Fold 10 accuracy: 73.68 %\n",
      "     Overall test accuracy: 73.98 %\n",
      "     Overall training accuracy: 97.96 %\n",
      "model  2 : Random Forest trees = 50\n",
      "   Fold 1 accuracy: 70.00 %\n",
      "   Fold 2 accuracy: 90.00 %\n",
      "   Fold 3 accuracy: 90.00 %\n",
      "   Fold 4 accuracy: 75.00 %\n",
      "   Fold 5 accuracy: 65.00 %\n",
      "   Fold 6 accuracy: 65.00 %\n",
      "   Fold 7 accuracy: 89.47 %\n",
      "   Fold 8 accuracy: 78.95 %\n",
      "   Fold 9 accuracy: 78.95 %\n",
      "   Fold 10 accuracy: 68.42 %\n",
      "     Overall test accuracy: 77.04 %\n",
      "     Overall training accuracy: 100.00 %\n",
      "model  3 : Random Forest trees = 100\n",
      "   Fold 1 accuracy: 75.00 %\n",
      "   Fold 2 accuracy: 70.00 %\n",
      "   Fold 3 accuracy: 90.00 %\n",
      "   Fold 4 accuracy: 85.00 %\n",
      "   Fold 5 accuracy: 85.00 %\n",
      "   Fold 6 accuracy: 65.00 %\n",
      "   Fold 7 accuracy: 78.95 %\n",
      "   Fold 8 accuracy: 73.68 %\n",
      "   Fold 9 accuracy: 63.16 %\n",
      "   Fold 10 accuracy: 68.42 %\n",
      "     Overall test accuracy: 75.51 %\n",
      "     Overall training accuracy: 100.00 %\n",
      "model  4 : Random Forest trees = 200\n",
      "   Fold 1 accuracy: 75.00 %\n",
      "   Fold 2 accuracy: 85.00 %\n",
      "   Fold 3 accuracy: 85.00 %\n",
      "   Fold 4 accuracy: 80.00 %\n",
      "   Fold 5 accuracy: 60.00 %\n",
      "   Fold 6 accuracy: 70.00 %\n",
      "   Fold 7 accuracy: 47.37 %\n",
      "   Fold 8 accuracy: 78.95 %\n",
      "   Fold 9 accuracy: 84.21 %\n",
      "   Fold 10 accuracy: 73.68 %\n",
      "     Overall test accuracy: 73.98 %\n",
      "     Overall training accuracy: 100.00 %\n",
      "model  5 : Random Forest trees = 300\n",
      "   Fold 1 accuracy: 75.00 %\n",
      "   Fold 2 accuracy: 80.00 %\n",
      "   Fold 3 accuracy: 70.00 %\n",
      "   Fold 4 accuracy: 70.00 %\n",
      "   Fold 5 accuracy: 90.00 %\n",
      "   Fold 6 accuracy: 75.00 %\n",
      "   Fold 7 accuracy: 47.37 %\n",
      "   Fold 8 accuracy: 78.95 %\n",
      "   Fold 9 accuracy: 89.47 %\n",
      "   Fold 10 accuracy: 84.21 %\n",
      "     Overall test accuracy: 76.02 %\n",
      "     Overall training accuracy: 100.00 %\n",
      "model  6 : Random Forest trees = 400\n",
      "   Fold 1 accuracy: 75.00 %\n",
      "   Fold 2 accuracy: 70.00 %\n",
      "   Fold 3 accuracy: 75.00 %\n",
      "   Fold 4 accuracy: 90.00 %\n",
      "   Fold 5 accuracy: 60.00 %\n",
      "   Fold 6 accuracy: 75.00 %\n",
      "   Fold 7 accuracy: 89.47 %\n",
      "   Fold 8 accuracy: 68.42 %\n",
      "   Fold 9 accuracy: 94.74 %\n",
      "   Fold 10 accuracy: 84.21 %\n",
      "     Overall test accuracy: 78.06 %\n",
      "     Overall training accuracy: 100.00 %\n",
      "model  7 : Random Forest trees = 500\n",
      "   Fold 1 accuracy: 80.00 %\n",
      "   Fold 2 accuracy: 70.00 %\n",
      "   Fold 3 accuracy: 70.00 %\n",
      "   Fold 4 accuracy: 65.00 %\n",
      "   Fold 5 accuracy: 60.00 %\n",
      "   Fold 6 accuracy: 80.00 %\n",
      "   Fold 7 accuracy: 94.74 %\n",
      "   Fold 8 accuracy: 78.95 %\n",
      "   Fold 9 accuracy: 84.21 %\n",
      "   Fold 10 accuracy: 68.42 %\n",
      "     Overall test accuracy: 75.00 %\n",
      "     Overall training accuracy: 100.00 %\n"
     ]
    }
   ],
   "source": [
    "model=0\n",
    "results = []\n",
    "cont = []\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "trees = [5, 10, 50, 100, 200, 300, 400, 500]\n",
    "for t in range(len(trees)):\n",
    "    fold = 1\n",
    "    truth = []\n",
    "    rf_prediction = []\n",
    "    print(\"model \", t, \": Random Forest trees = \" + str(trees[t]))\n",
    "    test_count = 0\n",
    "    rf = RandomForestClassifier(n_estimators=trees[t], criterion='entropy', n_jobs=-1, )\n",
    "    for train_idx, test_idx in kf.split(X):\n",
    "        trainX = X[train_idx]\n",
    "        trainY = Y[train_idx]\n",
    "        testX = X[test_idx]\n",
    "        testY = Y[test_idx]\n",
    "        truth.append(testY)\n",
    "        rf.fit(trainX, trainY)\n",
    "        Y_hat = rf.predict(testX)\n",
    "        rf_prediction.append(Y_hat)\n",
    "        print(\"   Fold %d accuracy: %.2f %%\" % (fold, ((np.sum(Y_hat == testY)/len(testY)) * 100.0)))                        \n",
    "        fold += 1\n",
    "    truth = np.concatenate(truth, axis=0)    \n",
    "    rf_prediction = np.concatenate(rf_prediction, axis=0)\n",
    "    test_results = np.sum(rf_prediction == truth)/len(truth)\n",
    "    print(\"     Overall test accuracy: %.2f %%\" % (test_results * 100))  \n",
    "    rf = rf.fit(X, Y)\n",
    "    Y_hat = rf.predict(X)\n",
    "    train_results = np.sum(Y_hat == Y)/len(Y)\n",
    "    print(\"     Overall training accuracy: %.2f %%\" % (train_results * 100.0))  \n",
    "    results.append([train_results, test_results])   \n",
    "    cont.append([truth, rf_prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Best Model: 6\n",
      "\n",
      "Random Forest\n",
      "         no  social  Total\n",
      "no       86      29    115\n",
      "social   14      67     81\n",
      "Total   100      96    196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = input(\"Enter Best Model: \")\n",
    "best = cont[int(model)]\n",
    "rf_ct = pd.crosstab(best[1], best[0], margins=True)\n",
    "rf_ct.columns = [\"no\", \"social\", \"Total\"]\n",
    "rf_ct.index = [\"no\", \"social\", \"Total\"]\n",
    "print()\n",
    "print(\"Random Forest\")\n",
    "print(rf_ct)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Sensitivity: 0.69792 Specificity: 0.86000 PPV: 0.82716 NPV: 0.74783 Accuracy: 0.78061\n"
     ]
    }
   ],
   "source": [
    "Sens = rf_ct.iloc[1][1]/rf_ct.iloc[2][1]\n",
    "Spec = rf_ct.iloc[0][0]/rf_ct.iloc[2][0]\n",
    "PPV = rf_ct.iloc[1][1]/rf_ct.iloc[1][2]\n",
    "NPV = rf_ct.iloc[0][0]/rf_ct.iloc[0][2]\n",
    "ACC = (rf_ct.iloc[0][0] + rf_ct.iloc[1][1]) / rf_ct.iloc[2][2]\n",
    "print(\"Random Forest: Sensitivity: %.5f Specificity: %.5f PPV: %.5f NPV: %.5f Accuracy: %.5f\" % (Sens, Spec, PPV, NPV, ACC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[86 14]\n",
      " [29 67]]\n",
      "0.757062146893\n",
      "0.697916666667\n",
      "0.827160493827\n",
      "0.780612244898\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.86      0.80       100\n",
      "          1       0.83      0.70      0.76        96\n",
      "\n",
      "avg / total       0.79      0.78      0.78       196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score,f1_score,precision_score,accuracy_score,classification_report\n",
    "y_true =cont[int(model)][0]\n",
    "y_pred = cont[int(model)][1]\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(f1_score(y_true, y_pred) )\n",
    "\n",
    "\n",
    "\n",
    "print(recall_score(y_true, y_pred),   )\n",
    "print(precision_score(y_true, y_pred))\n",
    "print(accuracy_score(y_true, y_pred))\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
